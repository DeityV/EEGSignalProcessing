{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100) (1000,)\n",
      "(1000, 100) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# example of creating a test dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "# create the inputs and outputs\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
    "# summarize the shape of the arrays\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "\n",
    "# example of creating a test dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "# create the inputs and outputs\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
    "# summarize the shape of the arrays\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  0.91\n",
      ">  0.95\n",
      ">  0.91\n",
      ">  0.93\n",
      ">  0.96\n",
      ">  0.93\n",
      ">  0.94\n",
      ">  0.93\n",
      ">  0.95\n",
      ">  0.9\n",
      "Mean: 0.931, Standard Deviation: 0.019\n",
      ">  0.92\n",
      ">  0.97\n",
      ">  0.97\n",
      ">  0.97\n",
      ">  0.95\n",
      ">  0.89\n",
      ">  0.93\n",
      ">  0.95\n",
      ">  0.95\n",
      ">  0.96\n",
      "Mean: 0.946, Standard Deviation: 0.025\n"
     ]
    }
   ],
   "source": [
    "# evaluate model by averaging performance across each fold\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# create the inputs and outputs\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
    "# k-fold cross validation\n",
    "scores = list()\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "# enumerate splits\n",
    "for train_ix, test_ix in kfold.split(X):\n",
    "\t# get data\n",
    "\ttrain_X, test_X = X[train_ix], X[test_ix]\n",
    "\ttrain_y, test_y = y[train_ix], y[test_ix]\n",
    "\t# fit model\n",
    "\tmodel = KNeighborsClassifier()\n",
    "\tmodel.fit(train_X, train_y)\n",
    "\t# evaluate model\n",
    "\tyhat = model.predict(test_X)\n",
    "\tacc = accuracy_score(test_y, yhat)\n",
    "\t# store score\n",
    "\tscores.append(acc)\n",
    "\tprint('> ', acc)\n",
    "# summarize model performance\n",
    "mean_s, std_s = mean(scores), std(scores)\n",
    "print('Mean: %.3f, Standard Deviation: %.3f' % (mean_s, std_s))\n",
    "\n",
    "# evaluate model by averaging performance across each fold\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# create the inputs and outputs\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
    "# k-fold cross validation\n",
    "scores = list()\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "# enumerate splits\n",
    "for train_ix, test_ix in kfold.split(X):\n",
    "\t# get data\n",
    "\ttrain_X, test_X = X[train_ix], X[test_ix]\n",
    "\ttrain_y, test_y = y[train_ix], y[test_ix]\n",
    "\t# fit model\n",
    "\tmodel = KNeighborsClassifier()\n",
    "\tmodel.fit(train_X, train_y)\n",
    "\t# evaluate model\n",
    "\tyhat = model.predict(test_X)\n",
    "\tacc = accuracy_score(test_y, yhat)\n",
    "\t# store score\n",
    "\tscores.append(acc)\n",
    "\tprint('> ', acc)\n",
    "# summarize model performance\n",
    "mean_s, std_s = mean(scores), std(scores)\n",
    "print('Mean: %.3f, Standard Deviation: %.3f' % (mean_s, std_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.954\n"
     ]
    }
   ],
   "source": [
    "# evaluate model by calculating the score across all predictions\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# create the inputs and outputs\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
    "# k-fold cross validation\n",
    "data_y, data_yhat = list(), list()\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "# enumerate splits\n",
    "for train_ix, test_ix in kfold.split(X):\n",
    "\t# get data\n",
    "\ttrain_X, test_X = X[train_ix], X[test_ix]\n",
    "\ttrain_y, test_y = y[train_ix], y[test_ix]\n",
    "\t# fit model\n",
    "\tmodel = KNeighborsClassifier()\n",
    "\tmodel.fit(train_X, train_y)\n",
    "\t# make predictions\n",
    "\tyhat = model.predict(test_X)\n",
    "\t# store\n",
    "\tdata_y.extend(test_y)\n",
    "\tdata_yhat.extend(yhat)\n",
    "# evaluate the model\n",
    "acc = accuracy_score(data_y, data_yhat)\n",
    "print('Accuracy: %.3f' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1 Accuracy: 0.755, Model2 Accuracy: 0.933\n",
      "Meta Model Accuracy: 0.942\n"
     ]
    }
   ],
   "source": [
    "# example of a stacked model for binary classification\n",
    "from numpy import hstack\n",
    "from numpy import array\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "# create a meta dataset\n",
    "def create_meta_dataset(data_x, yhat1, yhat2):\n",
    "\t# convert to columns\n",
    "\tyhat1 = array(yhat1).reshape((len(yhat1), 1))\n",
    "\tyhat2 = array(yhat2).reshape((len(yhat2), 1))\n",
    "\t# stack as separate columns\n",
    "\tmeta_X = hstack((data_x, yhat1, yhat2))\n",
    "\treturn meta_X\n",
    " \n",
    "# make predictions with stacked model\n",
    "def stack_prediction(model1, model2, meta_model, X):\n",
    "\t# make predictions\n",
    "\tyhat1 = model1.predict_proba(X)[:, 0]\n",
    "\tyhat2 = model2.predict_proba(X)[:, 0]\n",
    "\t# create input dataset\n",
    "\tmeta_X = create_meta_dataset(X, yhat1, yhat2)\n",
    "\t# predict\n",
    "\treturn meta_model.predict(meta_X)\n",
    " \n",
    "# create the inputs and outputs\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
    "# split\n",
    "X, X_val, y, y_val = train_test_split(X, y, test_size=0.33)\n",
    "# collect out of sample predictions\n",
    "data_x, data_y, knn_yhat, cart_yhat = list(), list(), list(), list()\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "for train_ix, test_ix in kfold.split(X):\n",
    "\t# get data\n",
    "\ttrain_X, test_X = X[train_ix], X[test_ix]\n",
    "\ttrain_y, test_y = y[train_ix], y[test_ix]\n",
    "\tdata_x.extend(test_X)\n",
    "\tdata_y.extend(test_y)\n",
    "\t# fit and make predictions with cart\n",
    "\tmodel1 = DecisionTreeClassifier()\n",
    "\tmodel1.fit(train_X, train_y)\n",
    "\tyhat1 = model1.predict_proba(test_X)[:, 0]\n",
    "\tcart_yhat.extend(yhat1)\n",
    "\t# fit and make predictions with cart\n",
    "\tmodel2 = KNeighborsClassifier()\n",
    "\tmodel2.fit(train_X, train_y)\n",
    "\tyhat2 = model2.predict_proba(test_X)[:, 0]\n",
    "\tknn_yhat.extend(yhat2)\n",
    "# construct meta dataset\n",
    "meta_X = create_meta_dataset(data_x, knn_yhat, cart_yhat)\n",
    "# fit final submodels\n",
    "model1 = DecisionTreeClassifier()\n",
    "model1.fit(X, y)\n",
    "model2 = KNeighborsClassifier()\n",
    "model2.fit(X, y)\n",
    "# construct meta classifier\n",
    "meta_model = LogisticRegression(solver='liblinear')\n",
    "meta_model.fit(meta_X, data_y)\n",
    "# evaluate sub models on hold out dataset\n",
    "acc1 = accuracy_score(y_val, model1.predict(X_val))\n",
    "acc2 = accuracy_score(y_val, model2.predict(X_val))\n",
    "print('Model1 Accuracy: %.3f, Model2 Accuracy: %.3f' % (acc1, acc2))\n",
    "# evaluate meta model on hold out dataset\n",
    "yhat = stack_prediction(model1, model2, meta_model, X_val)\n",
    "acc = accuracy_score(y_val, yhat)\n",
    "print('Meta Model Accuracy: %.3f' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
